{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VanillaGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daliavaleriani/gan/blob/master/VanillaGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "C_3IOWhpXR84",
        "colab_type": "code",
        "outputId": "d8cc781e-03dd-4518-8ab3-318865b08658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e2MbJPXtXVcP",
        "colab_type": "code",
        "outputId": "a307d9ff-5de7-4713-a6f9-f256d01ea14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6sxaw6B9ZUGa",
        "colab_type": "code",
        "outputId": "951182be-cae9-4961-ff15-6cba7866811e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CDmFrHkPYSRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QzzNJZEGYYKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Logger class\n",
        "# La classe Logger viene utilizzata per rendere l'output più gradevole e leggibile.\n",
        "# Ai fini del progetto non è stato ritenuto opportuno approfondire le sue funzionalità.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "\n",
        "'''\n",
        "    TensorBoard Data will be stored in './runs' path\n",
        "'''\n",
        "\n",
        "\n",
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PbcDjHF7YdTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Classe del Dataset\n",
        "\n",
        "def mnist_data():\n",
        "    # Si compongono diverse trasformazioni; ToTensor() converte immagini PIL in tensori;\n",
        "    # Normalize() normalizza un immagine del tensore con media e deviazione standard:\n",
        "    # la prima tupla rappreesenta la media e la seconda la deviazione standard.\n",
        "    compose = transforms.Compose( \n",
        "        [transforms.ToTensor(), \n",
        "         transforms.Normalize([0.5],[0.5])\n",
        "        ])\n",
        "    out_dir = './dataset'\n",
        "    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n",
        "\n",
        "# Load data\n",
        "data = mnist_data()\n",
        "\n",
        "# Si crea un loader con i dati, in modo da poterlo iterare.\n",
        "# batch_size = numero di campioni da caricare per un batch.\n",
        "# shuffle = True per avere i dati rimescolati in ogni epoca.\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
        "# Numero dei minibatch\n",
        "num_batches = len(data_loader)\n",
        "\n",
        "# N.B.: La lunghezza del loader si adatterà a batch_size.\n",
        "# Quindi, se il dataset ha 1000 campioni e si usa un batch_size di 10, il loader avrà lunghezza 100.\n",
        "# Infatti si utilizza il dataset MNIST che ha 60K esempi e un batch_size di 100: 60K/100=600 batches."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jeIruZB_ZkeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Discriminatore\n",
        "\n",
        "# torch.nn.Module = classe base per tutti i moduli della rete neurale.\n",
        "\n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Rete neurale discriminativa a tre strati nascosti\n",
        "    \"\"\"\n",
        "    # Questa rete acquisisce un'immagine appiattita come input e restituisce la probabilità che appartenga\n",
        "    # al set di dati reale o al dataset finto.\n",
        "    # La dimensione di input per ciascuna immagine sarà 28x28 = 784. \n",
        "    # Per quanto riguarda la struttura di questa rete, avrà tre livelli nascosti,\n",
        "    # ciascuno seguito dalla funzione di attivazione non lineare Leaky-ReLU e da un livello Dropout\n",
        "    # per evitare l'overfitting. Una funzione Sigmoid viene applicata all'output con valore reale\n",
        "    # per ottenere un valore nell'intervallo aperto (0, 1).\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 784\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            # nn.Linear(input, output)\n",
        "            nn.Linear(n_features, 1024),\n",
        "            # nn.LeakyReLU(negative_slope)\n",
        "            # La leakyReLU risolve il \"dying ReLU\" problem.\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # nn.Dropout(p) viene usato per ridurre l'overfitting. Ogni elemento di input ha una probabilità p\n",
        "            # di essere eliminato. Questa è una tecnica efficace per la regolarizzazione. Le uscite vengono\n",
        "            # ridimensionate di un fattore di 1/(1-p) durante l'allenamento. Una p di 0.5 (default) è\n",
        "            # accettabile per i livelli nascosti.\n",
        "            # A volte un p intorno a 0.2 funziona bene, ma dipende molto dal dataset di dati, quindi è\n",
        "            # compito dell'utente provare diverse combinazioni.\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(256, n_out),\n",
        "            #funzione di attivazione sigmoide\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "# Nella funzione seguente si definisce come verrà eseguito il modello, a partire dall'input fino all'output.\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "discriminator = DiscriminatorNet()\n",
        "\n",
        "if(torch.cuda.is_available):\n",
        "    discriminator = discriminator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_CICUhuZoc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dimensionality changing \n",
        "# Si necessita anche di alcune funzionalità aggiuntive che ci permettano di convertire un'immagine\n",
        "# appiattita nella sua rappresentazione bidimensionale, e un'altra che faccia il contrario.\n",
        "\n",
        "def images_to_vectors(images):\n",
        "    return images.view(images.size(0), 784)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "    return vectors.view(vectors.size(0), 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apQb5jVeZw95",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generatore\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Rete neurale generativa a tre strati nascosti\n",
        "    \"\"\"\n",
        "    # D'altra parte, la rete generativa prende un vettore variabile latente come input e restituisce\n",
        "    # un vettore di 784 valori, che corrisponde a un'immagine 28x28 appiattita.\n",
        "    # lo scopo di questa rete è imparare come creare immagini indistinguibili di cifre scritte a mano,\n",
        "    # motivo per cui il suo output è di per sé una nuova immagine. \n",
        "    # Questa rete avrà tre livelli nascosti, ciascuno seguito da una Leaky-ReLU.\n",
        "    # Lo strato di output avrà una funzione di attivazione di TanH, che mappa i valori risultanti nell'intervallo (-1, 1),\n",
        "    # che è lo stesso intervallo in cui le immagini MNIST pre-elaborate sono limitate.\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 100\n",
        "        n_out = 784\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden2 = nn.Sequential(\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(1024, n_out),\n",
        "            # Funzione di attivazione tangente iperbolica:\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.hidden2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "generator = GeneratorNet()\n",
        "\n",
        "if(torch.cuda.is_available):\n",
        "    generator = generator.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsVNyUhnZ0gx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Random noise sampler\n",
        "\n",
        "# Servono alcune funzionalità aggiuntive che consentano di creare il rumore casuale.\n",
        "# Il rumore casuale verrà campionato da una distribuzione normale con media 0 e varianza 1.\n",
        "\n",
        "def noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, 100))\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9m_eGXcGZ3lo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "\n",
        "# Qui si utilizzerà Adam come algoritmo di ottimizzazione per entrambe le reti neurali,\n",
        "# con un learning rate di 0.0002. \n",
        "\n",
        "# optim.Adam(params, learning_rate)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(),lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1t3w1ptZ6Wv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "\n",
        "# Binary Cross Entropy Loss: si prende la media della loss calcolata per ogni minibatch.\n",
        "# Questa è usata per misurare l'errore di ricostruzione.\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-oVu8jZZ-oC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Vettori target\n",
        "# Funzioni che aiuteranno in seguito nell'etichettatura (targeting) di immagini reali o false.\n",
        "# Infatti si può osservare che i target di immagini reali sono sempre 1, mentre quelli di immagini finte sono 0.\n",
        "\n",
        "def ones_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    return data\n",
        "\n",
        "def zeros_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SsoRFzqBaB2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Addestramento del discriminatore\n",
        "\n",
        "# Sommando le due loss del discriminatore, si ottengono la loss totale del mini-batch per il discriminatore.\n",
        "# In pratica, si calcoleranno i gradienti separatamente, per poi aggiornarli insieme.\n",
        "\n",
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "    N = real_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data.cuda())\n",
        "    prediction_real = prediction_real.cuda()\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real.cuda(), ones_target(N).cuda())\n",
        "    error_real = error_real.cuda()\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data.cuda())\n",
        "    prediction_fake = prediction_fake.cuda()\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake.cuda(), zeros_target(N).cuda())\n",
        "    error_fake = error_fake.cuda()\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_real + error_fake, prediction_real, prediction_fake"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BSBQvXAfaF-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Addestramento del generatore\n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "    N = fake_data.size(0)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data.cuda())\n",
        "    prediction = prediction.cuda()\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction.cuda(), ones_target(N).cuda())\n",
        "    error = error.cuda()\n",
        "    error.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Return error\n",
        "    return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OnZvsbGQaJXN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "# Numero di immagini che compaiono nell'output finale:\n",
        "\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HB9-2JG2aMGW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "# Si screa l'istanza di logger:\n",
        "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
        "\n",
        "# Numero totale di epoche da addestrare:\n",
        "num_epochs = 150\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "        N = real_batch.size(0)\n",
        "\n",
        "        # 1. Train Discriminator\n",
        "        real_data = Variable(images_to_vectors(real_batch).cuda())\n",
        "\n",
        "        # Generate fake data and detach \n",
        "        # (so gradients are not calculated for generator)\n",
        "        fake_data = generator((noise(N).cuda().detach()))\n",
        "\n",
        "        # Train D\n",
        "        d_error, d_pred_real, d_pred_fake = \\\n",
        "              train_discriminator(d_optimizer, real_data.cuda(), fake_data.cuda())\n",
        "\n",
        "        # 2. Train Generator\n",
        "\n",
        "        # Generate fake data\n",
        "        fake_data = generator(noise(N).cuda())\n",
        "\n",
        "        # Train G\n",
        "        g_error = train_generator(g_optimizer, fake_data)\n",
        "\n",
        "        # Log batch error\n",
        "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
        "\n",
        "        # Display Progress every few batches\n",
        "        if (n_batch) % 200 == 0: \n",
        "            test_images = vectors_to_images(generator(test_noise.cuda()))\n",
        "            test_images = test_images.data\n",
        "\n",
        "            logger.log_images(\n",
        "                test_images.cpu(), num_test_samples, \n",
        "                epoch, n_batch, num_batches\n",
        "            );\n",
        "            # Display status Logs\n",
        "            logger.display_status(\n",
        "                epoch, num_epochs, n_batch, num_batches,\n",
        "                d_error, g_error, d_pred_real, d_pred_fake\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}